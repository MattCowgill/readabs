% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api_chunk_api_url.R
\name{chunk_query_url}
\alias{chunk_query_url}
\title{Break up a \code{query_url} into chunks, by date and dimension}
\usage{
chunk_query_url(query_url, n = 300)
}
\arguments{
\item{query_url}{(character) the 'Data query' URL from the 'Developer API'
section from the \href{https://explore.data.abs.gov.au/}{ABS' API}. I'm not
sure what the difference between 'Flat' and 'Time series' is, because even
though the URLs are different they return the same data.}

\item{n}{(\code{numeric}; default = \code{300}) the number of dimension
levels to request in each URL. Higher means fewer URLs (and thus faster),
but increases the risk of the resulting URLs not being valid. Cursory
testing indicates that more than 400 results in data loss (ie some URLs are
still too big).}
}
\value{
(\code{character} vector) a \code{character} vector of URLs for the
  ABS API
}
\description{
Some URLs provided by the ABS' API are too long to actually work. This
function breaks up a \code{query_url} into multiple smaller ones. It does
this by looking at the time period the request covers, and separating it into
individual years, and by looking at the dimension with the most levels
(usually a geography) and creating URLs that only request a smaller number of
levels.
}
\examples{
\dontrun{
# This URL covers multiple years of data (it doesn't need to be chunked, it's
# just a toy example)
lf_url <- "https://api.data.abs.gov.au/data/ABS,LF,1.0.0/M9.3.1599.30+10+20.AUS.M?startPeriod=2010-02&endPeriod=2022-05&dimensionAtObservation=AllDimensions"

# Break it up into individual years
# Returns a URL for each year
lf_urls_years <- chunk_query_url(lf_url)

# Iterate over the vector of URLs
lf <- purrr::map_dfr(lf_urls_years, read_abs_api, batch_mode = TRUE)
}
}
